{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ee12505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Covid NLP from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d5c43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib import rc\n",
    "\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from pathlib import Path\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "#plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d79e6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hafidz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['does', 'how', \"should've\", 'up', 'ours', 'by', 'her', 've', 'hasn', 'm']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# View a few words from the set\n",
    "list(stop_words)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e93a4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper Function which generates random colors which can be used to give different colors to your plots\n",
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Simple function for random colours generation.\n",
    "    Input:\n",
    "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
    "    Output:\n",
    "        Color in the following format: ['#E86DA4'] .\n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e663e376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape\n",
      "  Downloading snscrape-0.3.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from snscrape) (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from snscrape) (4.11.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.8.0-cp37-cp37m-win_amd64.whl (3.6 MB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests[socks]->snscrape) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests[socks]->snscrape) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: PySocks, lxml, snscrape\n",
      "Successfully installed PySocks-1.7.1 lxml-4.8.0 snscrape-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9dcc04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f884fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:26:06.550330\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "# Creating list to append tweet data to\n",
    "tweets_longcovid = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('longcovid since:2021-01-01 until:2021-05-31 lang:en').get_items()):\n",
    "    if i>50000:\n",
    "        break\n",
    "    tweets_longcovid.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
    "end_time = datetime.now()\n",
    "    #Printing the time duration for scraping these tweets\n",
    "\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31d8d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe from the tweets list above and save it to csv\n",
    "tweets_longcovid_df = pd.DataFrame(tweets_longcovid, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "tweets_longcovid_df.to_csv(r'C:\\Users\\Hafidz\\PhDwork\\longcovidNLP\\tweets_longcovid_df50K.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3bd8eaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-30 23:59:29+00:00</td>\n",
       "      <td>1399153522545942531</td>\n",
       "      <td>@amyklobuchar @All100Senators Its not over, ev...</td>\n",
       "      <td>bargdaffy161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-30 23:55:37+00:00</td>\n",
       "      <td>1399152549345861647</td>\n",
       "      <td>@PatrickTrottie8 @driusan More people catch it...</td>\n",
       "      <td>zuckerman_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-30 23:53:36+00:00</td>\n",
       "      <td>1399152043269443589</td>\n",
       "      <td>@Huge761 @scotgov Case numbers mean a lot to t...</td>\n",
       "      <td>HelenSamfat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-30 23:50:06+00:00</td>\n",
       "      <td>1399151160536322056</td>\n",
       "      <td>Defies belief that a year on &amp;amp; after 150,0...</td>\n",
       "      <td>lottieflying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30 23:50:04+00:00</td>\n",
       "      <td>1399151151468187649</td>\n",
       "      <td>@apple_and_I Oh, I can totally relate to the n...</td>\n",
       "      <td>rtofthepossible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2021-05-30 23:59:29+00:00  1399153522545942531   \n",
       "1 2021-05-30 23:55:37+00:00  1399152549345861647   \n",
       "2 2021-05-30 23:53:36+00:00  1399152043269443589   \n",
       "3 2021-05-30 23:50:06+00:00  1399151160536322056   \n",
       "4 2021-05-30 23:50:04+00:00  1399151151468187649   \n",
       "\n",
       "                                                Text         Username  \n",
       "0  @amyklobuchar @All100Senators Its not over, ev...     bargdaffy161  \n",
       "1  @PatrickTrottie8 @driusan More people catch it...      zuckerman_l  \n",
       "2  @Huge761 @scotgov Case numbers mean a lot to t...      HelenSamfat  \n",
       "3  Defies belief that a year on &amp; after 150,0...     lottieflying  \n",
       "4  @apple_and_I Oh, I can totally relate to the n...  rtofthepossible  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 entries from dataframe\n",
    "tweets_longcovid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46df4297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'Tweet Id', 'Text', 'Username'], dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_longcovid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "13acdf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50001 entries, 0 to 50000\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype              \n",
      "---  ------    --------------  -----              \n",
      " 0   Datetime  50001 non-null  datetime64[ns, UTC]\n",
      " 1   Tweet Id  50001 non-null  int64              \n",
      " 2   Text      50001 non-null  object             \n",
      " 3   Username  50001 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_longcovid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d757720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_longcovid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7609190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: cached-property in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c0904274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: cached-property in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: torch in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: filelock in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTFBertForSequenceClassification requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38020\\4146043090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bert-base-uncased\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bert-base-uncased\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rstudio\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0mrequires_backends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rstudio\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \nTFBertForSequenceClassification requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install transformers\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from transformers import BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "77f222b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-30 23:59:29+00:00</td>\n",
       "      <td>1399153522545942531</td>\n",
       "      <td>@amyklobuchar @All100Senators Its not over, ev...</td>\n",
       "      <td>bargdaffy161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-30 23:55:37+00:00</td>\n",
       "      <td>1399152549345861647</td>\n",
       "      <td>@PatrickTrottie8 @driusan More people catch it...</td>\n",
       "      <td>zuckerman_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-30 23:53:36+00:00</td>\n",
       "      <td>1399152043269443589</td>\n",
       "      <td>@Huge761 @scotgov Case numbers mean a lot to t...</td>\n",
       "      <td>HelenSamfat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-30 23:50:06+00:00</td>\n",
       "      <td>1399151160536322056</td>\n",
       "      <td>Defies belief that a year on &amp;amp; after 150,0...</td>\n",
       "      <td>lottieflying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30 23:50:04+00:00</td>\n",
       "      <td>1399151151468187649</td>\n",
       "      <td>@apple_and_I Oh, I can totally relate to the n...</td>\n",
       "      <td>rtofthepossible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2021-05-30 23:59:29+00:00  1399153522545942531   \n",
       "1 2021-05-30 23:55:37+00:00  1399152549345861647   \n",
       "2 2021-05-30 23:53:36+00:00  1399152043269443589   \n",
       "3 2021-05-30 23:50:06+00:00  1399151160536322056   \n",
       "4 2021-05-30 23:50:04+00:00  1399151151468187649   \n",
       "\n",
       "                                                Text         Username  \n",
       "0  @amyklobuchar @All100Senators Its not over, ev...     bargdaffy161  \n",
       "1  @PatrickTrottie8 @driusan More people catch it...      zuckerman_l  \n",
       "2  @Huge761 @scotgov Case numbers mean a lot to t...      HelenSamfat  \n",
       "3  Defies belief that a year on &amp; after 150,0...     lottieflying  \n",
       "4  @apple_and_I Oh, I can totally relate to the n...  rtofthepossible  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating TRAIN dataset\n",
    "#Taking only 10,000 records and creating new dataframe called df1\n",
    "df50K_train = tweets_longcovid_df.head(10000)\n",
    "df50K_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3f88ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save into csv after applying stopwords\n",
    "df50K_train.to_csv(r'C:\\Users\\Hafidz\\PhDwork\\longcovidNLP\\df50K_train_10K.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "eb6406f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: cached-property in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: torch in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from torch) (3.10.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->transformers) (2.0.12)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38020\\4081011012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#sentiment_classifier = pipeline('sentiment-analysis', model=\"siebert/sentiment-roberta-large-english\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msentiment_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment-analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\rstudio\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rstudio\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         raise RuntimeError(\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;34m\"At least one of TensorFlow 2.0 or PyTorch should be installed. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m             \u001b[1;34m\"To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;34m\"To install PyTorch, read the instructions at https://pytorch.org/.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install transformers\n",
    "import torch\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import pipeline\n",
    "#sentiment_classifier = pipeline('sentiment-analysis', model=\"siebert/sentiment-roberta-large-english\")\n",
    "sentiment_classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cb605a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-30 23:59:29+00:00</td>\n",
       "      <td>1399153522545942531</td>\n",
       "      <td>@amyklobuchar @All100Senators Its not over, ev...</td>\n",
       "      <td>bargdaffy161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-30 23:55:37+00:00</td>\n",
       "      <td>1399152549345861647</td>\n",
       "      <td>@PatrickTrottie8 @driusan More people catch it...</td>\n",
       "      <td>zuckerman_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-30 23:53:36+00:00</td>\n",
       "      <td>1399152043269443589</td>\n",
       "      <td>@Huge761 @scotgov Case numbers mean a lot to t...</td>\n",
       "      <td>HelenSamfat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-30 23:50:06+00:00</td>\n",
       "      <td>1399151160536322056</td>\n",
       "      <td>Defies belief that a year on &amp;amp; after 150,0...</td>\n",
       "      <td>lottieflying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30 23:50:04+00:00</td>\n",
       "      <td>1399151151468187649</td>\n",
       "      <td>@apple_and_I Oh, I can totally relate to the n...</td>\n",
       "      <td>rtofthepossible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2021-05-30 23:59:29+00:00  1399153522545942531   \n",
       "1 2021-05-30 23:55:37+00:00  1399152549345861647   \n",
       "2 2021-05-30 23:53:36+00:00  1399152043269443589   \n",
       "3 2021-05-30 23:50:06+00:00  1399151160536322056   \n",
       "4 2021-05-30 23:50:04+00:00  1399151151468187649   \n",
       "\n",
       "                                                Text         Username  \n",
       "0  @amyklobuchar @All100Senators Its not over, ev...     bargdaffy161  \n",
       "1  @PatrickTrottie8 @driusan More people catch it...      zuckerman_l  \n",
       "2  @Huge761 @scotgov Case numbers mean a lot to t...      HelenSamfat  \n",
       "3  Defies belief that a year on &amp; after 150,0...     lottieflying  \n",
       "4  @apple_and_I Oh, I can totally relate to the n...  rtofthepossible  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50K_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a38ceb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycorenlp\n",
      "  Using cached pycorenlp-0.3.0.tar.gz (1.3 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from pycorenlp) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->pycorenlp) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->pycorenlp) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->pycorenlp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hafidz\\anaconda3\\envs\\rstudio\\lib\\site-packages (from requests->pycorenlp) (3.3)\n",
      "Building wheels for collected packages: pycorenlp\n",
      "  Building wheel for pycorenlp (setup.py): started\n",
      "  Building wheel for pycorenlp (setup.py): finished with status 'done'\n",
      "  Created wheel for pycorenlp: filename=pycorenlp-0.3.0-py3-none-any.whl size=2144 sha256=ecb2efc9384fb5b15fbc1fb4cf5f0a307b9591092fa7980f32144136bcb18c72\n",
      "  Stored in directory: c:\\users\\hafidz\\appdata\\local\\pip\\cache\\wheels\\83\\d8\\ad\\6b2276343ac605ee47e6beddb28331e96377909e5c816539c3\n",
      "Successfully built pycorenlp\n",
      "Installing collected packages: pycorenlp\n",
      "Successfully installed pycorenlp-0.3.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse import CoreNLPParser\n",
    "result = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "!{sys.executable} -m pip install pycorenlp\n",
    "import pycorenlp\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9026f3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had disturbed sleep for months, often I wake due to sounding like a Mongolian throat singer (see YouTube) half choking/gargling. Joked at first but should I worry? especially as the cat looks at me in a WTF/calculating how many meals I'd last it if I was to expire way! #LongCovid\n"
     ]
    }
   ],
   "source": [
    "print(tweets_longcovid_df['Text'][7890])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "69c67093",
   "metadata": {},
   "outputs": [],
   "source": [
    "trytext = \"My husband is trying an antihistamine diet to see if it helps with any of his long Covid symptoms and Im on dinner duty and good lord hes about to eat some boring fish.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6c40be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d9be0383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Datetime             Tweet Id  \\\n",
      "0     2021-05-30 23:59:29+00:00  1399153522545942531   \n",
      "1     2021-05-30 23:55:37+00:00  1399152549345861647   \n",
      "2     2021-05-30 23:53:36+00:00  1399152043269443589   \n",
      "3     2021-05-30 23:50:06+00:00  1399151160536322056   \n",
      "4     2021-05-30 23:50:04+00:00  1399151151468187649   \n",
      "...                         ...                  ...   \n",
      "49996 2021-04-25 21:28:07+00:00  1386431855616958465   \n",
      "49997 2021-04-25 21:26:46+00:00  1386431515437920257   \n",
      "49998 2021-04-25 21:26:05+00:00  1386431341722542081   \n",
      "49999 2021-04-25 21:25:41+00:00  1386431244049666051   \n",
      "50000 2021-04-25 21:24:33+00:00  1386430959310958593   \n",
      "\n",
      "                                                    Text         Username  \\\n",
      "0      @amyklobuchar @All100Senators Its not over, ev...     bargdaffy161   \n",
      "1      @PatrickTrottie8 @driusan More people catch it...      zuckerman_l   \n",
      "2      @Huge761 @scotgov Case numbers mean a lot to t...      HelenSamfat   \n",
      "3      Defies belief that a year on &amp; after 150,0...     lottieflying   \n",
      "4      @apple_and_I Oh, I can totally relate to the n...  rtofthepossible   \n",
      "...                                                  ...              ...   \n",
      "49996  Long COVID is probably just people drinking to...  harbinger______   \n",
      "49997  @DelusionalESG @whileURhere @AshterialWoW @the...   JoRichardsKent   \n",
      "49998  I had pretty bad side effects to the second sh...   johnmiltonoliv   \n",
      "49999  @EndzoneCone My focus is on infarct-induced da...        FizeekBio   \n",
      "50000  @ElectronNightm1 oh i see what you mean. if i ...     claireternal   \n",
      "\n",
      "                                 tweet_without_stopwords  \n",
      "0      @amyklobuchar @All100Senators Its over, ever h...  \n",
      "1      @PatrickTrottie8 @driusan More people catch it...  \n",
      "2      @Huge761 @scotgov Case numbers mean lot left h...  \n",
      "3      Defies belief year &amp; 150,000 people lost l...  \n",
      "4      @apple_and_I Oh, I totally relate need vent! I...  \n",
      "...                                                  ...  \n",
      "49996  Long COVID probably people drinking much quara...  \n",
      "49997  @DelusionalESG @whileURhere @AshterialWoW @the...  \n",
      "49998  I pretty bad side effects second shot. 36 hour...  \n",
      "49999  @EndzoneCone My focus infarct-induced damage, ...  \n",
      "50000  @ElectronNightm1 oh see mean. them, wouldnt e...  \n",
      "\n",
      "[50001 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "tweets_longcovid_df = tweets_longcovid_df.loc[:,[\"Datetime\",\"Tweet Id\",\"Text\", \"Username\"]]\n",
    "# Exclude stopwords \n",
    "tweets_longcovid_df['tweet_without_stopwords'] = tweets_longcovid_df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print(tweets_longcovid_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
